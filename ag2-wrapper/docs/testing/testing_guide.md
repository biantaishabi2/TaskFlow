# AG2-Wrapper 测试指南

本文档提供了测试 AG2-Wrapper 的指南，从最小单元测试开始逐步扩展到功能测试和集成测试。

## 环境配置

在开始测试前，确保已正确设置环境：

1. 激活包含 AutoGen 的 conda 环境 (ag2)
2. 安装 AG2-Wrapper 及其开发依赖
3. 确认环境变量中已设置 OPENROUTER_API_KEY

## LLM API 配置

AG2-Wrapper 测试将使用 OpenRouter API 与 `openai/gpt-4o-mini` 模型。使用环境变量中已有的 OPENROUTER_API_KEY 进行认证，并使用 OpenAI 客户端通过 OpenRouter 的 API 端点访问模型。

## 测试层次

测试将按以下层次进行：

### 1. 单元测试

从最小单元开始进行测试：

#### 1.1 配置模块测试
- 测试配置创建函数 (create_openai_config, create_openrouter_config)
- 测试 ConfigManager 类的配置加载、保存和获取功能
- 验证所有生成的配置符合 AutoGen 要求格式

#### 1.2 工具模块测试
- 测试工具注册功能
- 测试工具执行功能
- 测试工具错误处理
- 验证工具描述和参数提取正确

#### 1.3 工具适配器测试
- 测试外部工具管理器适配器
- 验证工具执行结果格式转换
- 测试错误处理和工具未找到情况

### 2. OpenRouter LLM 测试

使用环境中已有的 OpenRouter API 密钥测试 LLM 调用功能：

- 测试基本的文本生成
- 验证响应格式和内容
- 测试各种提示和系统消息
- 测试中文输入和输出

### 3. 对话模式组件测试

#### 3.1 TwoAgentChat 测试
- 测试初始化和配置
- 测试对话启动和继续
- 测试工具使用
- 测试对话历史记录

#### 3.2 其他对话模式测试 (后续实现)
- 测试 SequentialChat 组件
- 测试 GroupChat 组件
- 测试 NestedChat 组件
- 测试 Swarm 组件

### 4. 集成测试

测试所有组件的协同工作：

- 测试 AG2Wrapper 与对话模式集成
- 测试工具管理器与对话集成
- 测试配置管理与对话集成
- 测试完整的用户场景

### 5. 端到端功能测试

- 测试真实世界的使用场景
- 执行完整的多轮对话
- 使用复杂工具和配置
- 验证系统行为与预期一致

## 重要测试原则

1. **使用真实 API 调用**：所有测试都应使用真实的 OpenRouter API 调用，以确保系统在实际环境中正常工作。不需要考虑 API 使用限制或费用问题。

2. **全面测试覆盖**：确保测试覆盖所有组件和功能，包括边缘情况和错误处理。

3. **自动化测试**：使用 pytest 框架自动化测试流程，确保所有测试可重复执行。

4. **逐步测试**：先测试基础组件，再测试集成功能，最后进行端到端测试。

5. **详细日志记录**：记录所有测试结果和 API 交互，便于问题排查和性能优化。

## 测试运行步骤

1. 创建测试文件结构
2. 实现各级别测试用例
3. 使用 pytest 运行测试
4. 分析测试结果和日志
5. 根据测试结果优化系统