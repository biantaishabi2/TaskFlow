#!/usr/bin/env python3
"""
Example demonstrating the group chat mode in AG2-Engine.

This example shows how to create and use a group chat where multiple specialized agents
discuss a topic together, with a facilitator guiding the conversation.

The GroupChat mode supports:
- Multiple agents participating in a discussion together
- Round-robin or custom speaking order
- Facilitated discussion with a designated facilitator agent
- Multiple discussion rounds with configurable maximum
"""

import sys
import os
import logging
import asyncio
from typing import Dict, Any, List, Optional

# Add the parent directory to sys.path to import the package
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from ag2_engine.ag2_executor import AG2Executor

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


async def main():
    """Main example function."""
    try:
        # Check for OpenRouter API key
        if not os.environ.get("OPENROUTER_API_KEY"):
            print("âš ï¸ OpenRouter API key not found. Please set OPENROUTER_API_KEY environment variable.")
            return
        
        # Configuration for AG2Executor
        config = {
            "agents": {
                "tech_expert": {
                    "name": "æŠ€æœ¯ä¸“å®¶",
                    "type": "llm",
                    "system_message": "ä½ æ˜¯ä¸€ä½äººå·¥æ™ºèƒ½é¢†åŸŸçš„æŠ€æœ¯ä¸“å®¶ã€‚ä½ æä¾›å…³äºAIèƒ½åŠ›å’Œå±€é™æ€§çš„äº‹å®æ€§ã€æŠ€æœ¯æ€§è§è§£ã€‚"
                                    "è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šä¸”é€šä¿—æ˜“æ‡‚çš„è¯­è¨€é£æ ¼ã€‚",
                    "llm_config": {
                        "config_list": [
                            {
                                "api_type": "openai",
                                "model": "google/gemini-2.0-flash-lite-001",
                                "temperature": 0.7,
                                "api_key": "${OPENROUTER_API_KEY}",
                                "base_url": "https://openrouter.ai/api/v1",
                                "extra_headers": {
                                    "HTTP-Referer": "https://github.com/anthropics/claude-code",
                                    "X-Title": "AG2-Agent-Group-Chat",
                                }
                            }
                        ]
                    }
                },
                "ethicist": {
                    "name": "ä¼¦ç†ä¸“å®¶",
                    "type": "llm",
                    "system_message": "ä½ æ˜¯ä¸€ä½AIä¼¦ç†ä¸“å®¶ï¼Œåœ¨åè§ã€å…¬å¹³æ€§å’ŒAIæŠ€æœ¯çš„ç¤¾ä¼šå½±å“æ–¹é¢æœ‰ä¸“ä¸šçŸ¥è¯†ã€‚"
                                    "åœ¨è®¨è®ºAIéƒ¨ç½²æ—¶ï¼Œä½ ä¼šæå‡ºé‡è¦çš„ä¼¦ç†è€ƒé‡ã€‚è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šä¸”é€šä¿—æ˜“æ‡‚çš„è¯­è¨€é£æ ¼ã€‚",
                    "llm_config": {
                        "config_list": [
                            {
                                "api_type": "openai",
                                "model": "google/gemini-2.0-flash-lite-001",
                                "temperature": 0.7,
                                "api_key": "${OPENROUTER_API_KEY}",
                                "base_url": "https://openrouter.ai/api/v1",
                                "extra_headers": {
                                    "HTTP-Referer": "https://github.com/anthropics/claude-code",
                                    "X-Title": "AG2-Agent-Group-Chat",
                                }
                            }
                        ]
                    }
                },
                "product_manager": {
                    "name": "äº§å“ç»ç†",
                    "type": "llm",
                    "system_message": "ä½ æ˜¯ä¸€ä½ä¸“æ³¨äºAIå®é™…åº”ç”¨çš„äº§å“ç»ç†ã€‚ä½ æ€è€ƒå¸‚åœºéœ€æ±‚ã€ç”¨æˆ·ä½“éªŒå’Œå•†ä¸šå¯è¡Œæ€§ã€‚"
                                    "è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šä¸”é€šä¿—æ˜“æ‡‚çš„è¯­è¨€é£æ ¼ã€‚",
                    "llm_config": {
                        "config_list": [
                            {
                                "api_type": "openai",
                                "model": "google/gemini-2.0-flash-lite-001",
                                "temperature": 0.7,
                                "api_key": "${OPENROUTER_API_KEY}",
                                "base_url": "https://openrouter.ai/api/v1",
                                "extra_headers": {
                                    "HTTP-Referer": "https://github.com/anthropics/claude-code",
                                    "X-Title": "AG2-Agent-Group-Chat",
                                }
                            }
                        ]
                    }
                },
                "facilitator": {
                    "name": "è®¨è®ºå¼•å¯¼è€…",
                    "type": "llm",
                    "system_message": "ä½ æ˜¯ä¸€ä½æŠ€å·§å¨´ç†Ÿçš„è®¨è®ºå¼•å¯¼è€…ã€‚ä½ çš„è§’è‰²æ˜¯æ€»ç»“å…³é”®ç‚¹ã€æ‰¾å‡ºæ„è§ä¸€è‡´/åˆ†æ­§çš„é¢†åŸŸï¼Œ"
                                    "å¹¶å¼•å¯¼å¯¹è¯æœç€å¯Œæœ‰æˆæ•ˆçš„ç»“æœå‘å±•ã€‚è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒç®€æ´æ˜äº†çš„å¼•å¯¼é£æ ¼ã€‚",
                    "llm_config": {
                        "config_list": [
                            {
                                "api_type": "openai",
                                "model": "google/gemini-2.0-flash-lite-001",
                                "temperature": 0.7,
                                "api_key": "${OPENROUTER_API_KEY}",
                                "base_url": "https://openrouter.ai/api/v1",
                                "extra_headers": {
                                    "HTTP-Referer": "https://github.com/anthropics/claude-code",
                                    "X-Title": "AG2-Agent-Group-Chat",
                                }
                            }
                        ]
                    }
                }
            },
            "chat_settings": {
                "mode": "group_chat",
                "config": {
                    "max_rounds": 3,
                    "facilitator": "facilitator",
                    "speaking_order": "round_robin"
                }
            }
        }
        
        # Create AG2Executor instance
        executor = AG2Executor(config)
        
        # Start group discussion
        print("\nğŸ”„ å¼€å§‹ç¾¤ç»„è®¨è®º...\n")
        initial_message = (
            "è®©æˆ‘ä»¬è®¨è®ºåœ¨åŒ»ç–—ä¿å¥é¢†åŸŸéƒ¨ç½²AIç³»ç»Ÿçš„æ½œåœ¨ç›Šå¤„å’Œé£é™©ã€‚"
            "è¯·è€ƒè™‘è¯Šæ–­åº”ç”¨ã€æ²»ç–—å»ºè®®ã€è¡Œæ”¿æ•ˆç‡ã€éšç§é—®é¢˜å’Œä¼¦ç†å½±å“ç­‰æ–¹é¢ã€‚"
        )
        
        # Set up a message printer
        def print_message(data):
            sender = data.get('sender', 'Unknown')
            message = data.get('message', '')
            print(f"\nğŸ’¬ {sender}: {message}")
            print("-" * 50)
        
        # Execute the task with group chat mode
        context = {"topic": "AIåœ¨åŒ»ç–—é¢†åŸŸï¼šæ½œåœ¨ç›Šå¤„ä¸é£é™©"}
        
        result = await executor.execute_async(
            initial_message,
            mode="group_chat",
            agents={
                "facilitator": "facilitator", 
                "tech_expert": "tech_expert", 
                "ethicist": "ethicist",
                "product_manager": "product_manager"
            },
            context=context,
            callbacks={
                'response_received': print_message,
                'message_sent': print_message
            }
        )
        
        # Display summary
        print("\n=== è®¨è®ºæ‘˜è¦ ===")
        if 'turn_count' in result:
            print(f"æ€»å›åˆæ•°: {result['turn_count']}")
        if 'message_count' in result:
            print(f"æ€»æ¶ˆæ¯æ•°: {result['message_count']}")
        
        print("\nâœ… ç¾¤ç»„è®¨è®ºç¤ºä¾‹å®Œæˆ\n")
        
    except Exception as e:
        logger.error(f"Error in group chat example: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())